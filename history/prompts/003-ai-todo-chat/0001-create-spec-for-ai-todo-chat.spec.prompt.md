---
id: 0001
title: Create Spec for AI Todo Chat
stage: spec
date: 2026-01-07
surface: agent
model: gemini-2.0-flash-exp
feature: 003-ai-todo-chat
branch: 003-ai-todo-chat
user: User
command: /sp.specify
labels: ["spec", "ai", "mcp"]
links:
  spec: specs/003-ai-todo-chat/spec.md
  ticket: null
  adr: null
  pr: null
files:
 - specs/003-ai-todo-chat/spec.md
 - specs/003-ai-todo-chat/checklists/requirements.md
tests:
 - none
---

## Prompt

Phase III: AI-Powered Todo Chatbot with MCP Server Project Context: Phase III of Evolution of Todo hackathon. Adds conversational AI interface to Phase II web app. Users manage todos through natural language chat powered by Gemini 2.5 Flash. MCP server exposes todo operations as tools the AI agent can invoke. Target Audience: - Hackathon judges evaluating AI integration and MCP architecture - Users who prefer conversational interfaces over forms - Developers learning agentic AI and MCP protocol Intent: Build an AI chatbot that understands natural language todo commands and executes them via MCP tools. The chat endpoint is stateless (no in-memory state), conversation history persists in database, and the AI agent uses Gemini function calling to invoke MCP tools. Core Features (Phase II + Conversational Interface): 1. Custom Chat UI - React components for chat interface (no OpenAI ChatKit) 2. Gemini 2.5 Flash - Free tier AI model for natural language understanding 3. MCP Server - Official MCP SDK exposing 5 todo operation tools 4. Stateless Chat API - Conversation state stored in Neon DB 5. Natural Language Commands - "Add task to buy groceries", "Show my pending tasks" Success Criteria (SMART): - User can chat with AI to manage all 5 Basic Level todo operations - Chat UI displays user messages and AI responses in a conversation thread - AI agent understands natural language task commands (tested with 10+ variations) - MCP server exposes exactly 5 tools: add_task, list_tasks, complete_task, delete_task, update_task - Chat endpoint is stateless (server can restart without losing conversation history) - Conversation history stored in Neon DB (conversations and messages tables) - AI responses include confirmation of actions taken ("Task 'Buy groceries' created") - Gemini API rate limits respected (15 RPM, 1M TPM tracked in logs) - All Phase II features still work (web form UI remains functional) - Tests covering MCP tools, chat endpoint, conversation persistence - 80%+ coverage on chatbot business logic - All code generated via Gemini CLI (prompt history documented) Technical Stack (from Constitution): AI Model: - Gemini 2.5 Flash (free tier) - API Key: GEMINI_API_KEY environment variable - Function Calling: Enable for MCP tool invocation - Rate Limits: 15 RPM, 1M TPM (log usage) Chat UI (Custom): - Components: Message, ChatInput, MessageList, ChatContainer - Styling: Tailwind CSS - State: useState for messages, useEffect for scrolling - NO OpenAI ChatKit (build custom React components) MCP Server: - SDK: Official MCP SDK (Python) - Protocol: HTTP/SSE (Server-Sent Events) for streaming (optional Phase III) - Tools: 5 required (add_task, list_tasks, complete_task, delete_task, update_task) - Stateless: NO in-memory state, all data in Neon DB Chat Architecture (Stateless): 1. User sends message ‚Üí POST /api/{user_id}/chat 2. Backend fetches conversation history from DB 3. Backend calls Gemini API with history + new message + MCP tools definition 4. Gemini invokes MCP tools (function calling) as needed 5. Backend executes tool calls, gets results 6. Backend stores user message + assistant response in DB 7. Backend returns assistant response to frontend 8. Server holds NO state (ready for next request) Database Schema (New Tables): Table: conversations - id: serial (primary key) - user_id: UUID (foreign key -> users.id, ON DELETE CASCADE) - created_at: timestamp (default now) - updated_at: timestamp (auto-update) Table: messages - id: serial (primary key) - user_id: UUID (foreign key -> users.id, ON DELETE CASCADE) - conversation_id: integer (foreign key -> conversations.id, ON DELETE CASCADE) - role: enum('user', 'assistant') (not null) - content: text (not null) - created_at: timestamp (default now) Indexes: - messages.conversation_id (for history fetching) - messages.user_id (for user isolation) MCP Tools Specification: Tool: add_task Input: {user_id: string, title: string, description?: string} Output: {task_id: int, status: "created", title: string} Example: User: "Add a task to buy groceries" AI calls: add_task(user_id="...", title="Buy groceries") Tool: list_tasks Input: {user_id: string, status?: "all"|"pending"|"completed"} Output: [{id: int, title: string, completed: bool, created_at: string}, ...] Example: User: "Show my pending tasks" AI calls: list_tasks(user_id="...", status="pending") Tool: complete_task Input: {user_id: string, task_id: int} Output: {task_id: int, status: "completed", title: string} Example: User: "Mark task 3 as done" AI calls: complete_task(user_id="...", task_id=3) Tool: delete_task Input: {user_id: string, task_id: int} Output: {task_id: int, status: "deleted", title: string} Example: User: "Delete the grocery task" AI first calls list_tasks to find ID, then delete_task(...) Tool: update_task Input: {user_id: string, task_id: int, title?: string, description?: string} Output: {task_id: int, status: "updated", title: string} Example: User: "Change task 1 to 'Buy groceries and fruits'" AI calls: update_task(user_id="...", task_id=1, title="...") Natural Language Commands to Support: - Task Creation: "Add task to X", "Remember to X", "I need to X" - Task Listing: "Show tasks", "What's on my list", "What's pending", "What did I complete" - Task Completion: "Mark X as done", "I finished X", "Complete task X" - Task Deletion: "Delete X", "Remove the X task", "Cancel X" - Task Update: "Change X to Y", "Update X", "Rename X" - Mixed: "Add 'Buy milk' and show my list" Agent Behavior (from Constitution): - ALWAYS confirm actions: "Task 'Buy groceries' created" (not just "Done") - Use friendly tone: "Sure! I've added that task for you." - Handle errors gracefully: "I couldn't find a task with that ID. Would you like to see your list?" - If ambiguous, ask clarification: "Which task did you want to delete? You have 2 tasks with 'meeting' in the title." Quality Standards (from Constitution): - Stateless server (no conversation state in memory) - Conversation history fetched from DB on every request - MCP tools are also stateless (no cached data) - Gemini rate limits tracked (log warning at 80% usage) - All errors handled gracefully (API errors, DB errors, tool errors) - Tests covering: tool invocation, conversation persistence, natural language parsing - 80%+ coverage on chatbot logic User Scenarios: 1. User opens chat ‚Üí sends "Add task to buy groceries" ‚Üí AI responds "Task created!" ‚Üí task appears in list 2. User sends "Show my tasks" ‚Üí AI lists all tasks with status 3. User sends "Mark task 3 as done" ‚Üí AI confirms completion 4. User closes browser ‚Üí reopens chat ‚Üí conversation history restored from DB 5. User sends ambiguous command ‚Üí AI asks for clarification 6. Server restarts during conversation ‚Üí user continues chat without losing history Edge Cases to Handle: - User sends message with no clear intent ("hello", "what's up") - User references non-existent task ID - User sends command while server is processing previous command - Gemini API rate limit exceeded (return 429 with retry message) - Gemini API timeout (return 503 with retry message) - Database connection lost during chat (return 500 with error message) - User sends very long message (>1000 chars) - truncate or reject - Conversation history too long (>10 messages) - summarize or paginate Not Building (Non-Goals): - Voice input/output (Phase V bonus feature) - Multi-language support (Phase V bonus feature) - Streaming responses (optional in Phase III, can defer) - Multi-turn planning (AI handles one command at a time) - Task scheduling/reminders (Phase V with Dapr Jobs API) - File attachments in chat - Image understanding (task descriptions from images) Acceptance Criteria Checklist: [ ] Custom chat UI working (React components styled with Tailwind) [ ] User can manage all 5 Basic Level operations via natural language [ ] MCP server exposes exactly 5 tools with correct schemas [ ] Gemini 2.5 Flash integrated with function calling enabled [ ] Chat endpoint is stateless (conversation state in DB) [ ] Conversation history persists across sessions [ ] AI confirms actions with friendly messages [ ] Errors handled gracefully with user-friendly messages [ ] Tests covering MCP tools and chat endpoint (80%+ coverage) [ ] Phase II web form UI still works (not removed) [ ] README includes chat usage examples [ ] Prompt history documented in specs/history/phase-3-prompts.md Timeline: Complete by: December 21, 2025 (Phase III deadline) Estimated Effort: 10-15 hours (MCP server, Gemini integration, chat UI, testing) Deliverables: 1. Updated monorepo: - /frontend (with chat UI components) - /backend (with MCP server and chat endpoint) - /specs (Phase III spec, prompt history) - README (chat usage examples) 2. Deployed app with working chatbot (Vercel + backend) 3. Demo video (max 90 seconds showing natural language task management) Definition of Done: - All acceptance criteria checked - Chatbot working for all 5 Basic Level operations - MCP server functional with 5 tools - Conversation history persisting in DB - Stateless architecture verified (tested with server restart) - Tests passing (80%+ coverage) - Deployed and accessible - Demo video recorded showing conversational interface

## Response snapshot

Created feature branch `003-ai-todo-chat`, generated specification matching Phase III requirements, and validated quality checklist.

## Outcome

- ‚úÖ Impact: Spec created
- üß™ Tests: N/A
- üìÅ Files: Spec and checklist created
- üîÅ Next prompts: /sp.plan
- üß† Reflection: Smooth generation from detailed user input.

## Evaluation notes (flywheel)

- Failure modes observed: None
- Graders run and results (PASS/FAIL): PASS
- Prompt variant (if applicable): default
- Next experiment (smallest change to try): None